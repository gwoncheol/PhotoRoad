import os
import torch
import clip
from PIL import Image
import pickle
import csv

# ê²½ë¡œ ì„¤ì •
image_folder = "JejuImage"
csv_file = "ImageLabelsEnbedding/labels2.csv"
embedding_cache_file = "ImageLabelsEnbedding/image_embeddings3.pkl"

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = "cuda" if torch.cuda.is_available() else "cpu"

# CLIP ëª¨ë¸ ë¡œë“œ
print("â³ CLIP ëª¨ë¸ ë¡œë“œ ì¤‘...")
model, preprocess = clip.load("ViT-B/32", device)
print("âœ… CLIP ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

# ì´ë¯¸ì§€ ê²½ë¡œ ë° í…ìŠ¤íŠ¸ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
image_paths = []
text_labels = []

# CSV íŒŒì¼ ì½ê¸°
with open(csv_file, newline="", encoding="utf-8") as f:
    reader = csv.reader(f)
    next(reader)  # í—¤ë” ê±´ë„ˆë›°ê¸°
    for row in reader:
        image_name = row[0]
        image_path_jpg = os.path.join(image_folder, image_name + ".jpg")
        image_path_png = os.path.join(image_folder, image_name + ".png")

        # ì¡´ì¬í•˜ëŠ” íŒŒì¼ í™•ì¥ì ìë™ ê°ì§€
        if os.path.isfile(image_path_jpg):
            image_paths.append(image_path_jpg)
            text_labels.append(row[1])
        elif os.path.isfile(image_path_png):
            image_paths.append(image_path_png)
            text_labels.append(row[1])
        else:
            print(f"âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {image_name}")

print(f"ğŸ” {len(image_paths)}ê°œì˜ ì´ë¯¸ì§€ì™€ {len(text_labels)}ê°œì˜ í…ìŠ¤íŠ¸ ë¼ë²¨ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

# ì´ë¯¸ì§€ ì„ë² ë”© ê³„ì‚°
print("â³ ì´ë¯¸ì§€ ì„ë² ë”© ê³„ì‚° ì‹œì‘...")
image_features = {}
for path in image_paths:
    try:
        image = Image.open(path).convert("RGB")
        image_input = preprocess(image).unsqueeze(0).to(device)
        with torch.no_grad():
            image_feature = model.encode_image(image_input).cpu().numpy()
        image_features[path] = image_feature
    except Exception as e:
        print(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {path}, ì—ëŸ¬: {e}")

# í…ìŠ¤íŠ¸ ì„ë² ë”© ê³„ì‚° - ë°°ì¹˜ ì²˜ë¦¬
print("â³ í…ìŠ¤íŠ¸ ì„ë² ë”© ê³„ì‚° ì‹œì‘...")
batch_size = 256
text_features = []

for i in range(0, len(text_labels), batch_size):
    batch_texts = text_labels[i:i + batch_size]
    text_inputs = clip.tokenize(batch_texts).to(device)
    with torch.no_grad():
        batch_features = model.encode_text(text_inputs).cpu()
    text_features.append(batch_features)

# ëª¨ë“  ë°°ì¹˜ ê²°ê³¼ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹¨
text_features = torch.cat(text_features, dim=0).numpy()
print(f"âœ… í…ìŠ¤íŠ¸ ì„ë² ë”© ê³„ì‚° ì™„ë£Œ: {len(text_features)}ê°œì˜ í…ìŠ¤íŠ¸ ì„ë² ë”©")

# ì„ë² ë”© ë° ë¼ë²¨ì„ pkl íŒŒì¼ë¡œ ì €ì¥
try:
    with open(embedding_cache_file, "wb") as f:
        pickle.dump((image_features, text_features, text_labels), f)
    print(f"âœ… ì´ë¯¸ì§€ ë° í…ìŠ¤íŠ¸ ì„ë² ë”© ì €ì¥ ì™„ë£Œ: {embedding_cache_file}")
except Exception as e:
    print(f"âš ï¸ ì„ë² ë”© ì €ì¥ ì‹¤íŒ¨, ì—ëŸ¬: {e}")
